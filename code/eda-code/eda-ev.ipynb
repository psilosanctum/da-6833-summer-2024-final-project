{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"EV Exploratory Data Analysis\"\n",
        "date: today\n",
        "output: html_document\n",
        "execute: \n",
        "  error: False\n",
        "  warning: False\n",
        "---"
      ],
      "id": "82c0f7fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n"
      ],
      "id": "8b615215"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#load needed packages. make sure they are installed.\n",
        "from pandas import read_csv, set_option, merge, DataFrame, concat, read_json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import statsmodels.api as sm\n",
        "import statsmodels\n",
        "from statsmodels.graphics.gofplots import ProbPlot\n",
        "from scipy import stats\n",
        "import geojson\n",
        "import folium\n",
        "import json\n",
        "set_option('display.max_columns', None)"
      ],
      "id": "e44ec4de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data.\n"
      ],
      "id": "c5276e8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "base_dir = '../../'\n",
        "df = read_csv(base_dir + 'data/processed-data/brand_model_year_tax_data.csv')\n",
        "columns_list = df.columns.tolist()\n",
        "for i in columns_list:\n",
        "    print(i.strip())\n",
        "numeric_cols = columns_list[28:]\n",
        "df.columns.tolist()"
      ],
      "id": "6cb52d83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vehicle Brand Aggregation"
      ],
      "id": "3bc1b3ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.set_style('darkgrid')\n",
        "zip_code_count = df.groupby(['ZIPCODE']).agg({\n",
        "    'Vehicle Count': 'sum',\n",
        "}).reset_index()\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.histplot(ax=axes[0], data=zip_code_count, y=zip_code_count['Vehicle Count'])\n",
        "log_zip_code_count = zip_code_count.copy()\n",
        "log_zip_code_count['Vehicle Count'] = np.log(zip_code_count['Vehicle Count'])\n",
        "sns.histplot(ax=axes[1], data=log_zip_code_count, y=log_zip_code_count['Vehicle Count'])\n",
        "zip_code_count"
      ],
      "id": "699d3028",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "us_zips_df = read_csv(base_dir + 'data/raw-data/uszips.csv')\n",
        "wa_zips = us_zips_df.loc[us_zips_df['state_id'] == 'WA']\n",
        "wa_zips = wa_zips[['ZIPCODE', 'lat', 'lng', 'population']]\n",
        "merge_zips = merge(wa_zips, zip_code_count, on='ZIPCODE')\n",
        "# print(merge_zips)\n",
        "test = base_dir + 'data/raw-data/counties.geojson'\n",
        "with open(test) as f:\n",
        "    gj = geojson.load(f)\n",
        "    # print(gj['features'])\n",
        "# countries = [\"53\"]\n",
        "# new_list = []\n",
        "# features = gj['features'][0]['properties']['STATEFP']\n",
        "features = gj['features']\n",
        "print(features[0])\n",
        "# for i in features:\n",
        "#     # print(i)\n",
        "#     if i['properties']['STATEFP'] == '53':\n",
        "#         new_list.append(i)\n",
        "#     else:\n",
        "#         pass\n",
        "# final = json.dumps(new_list, indent=2)\n",
        "# print(gj)\n",
        "mapit = folium.Map(location=[122.511983, 37.77113])\n",
        "\n",
        "for i in features:\n",
        "    if i['properties']['STATEFP'] == '53':\n",
        "        print(i)\n",
        "        folium.Choropleth(geo_data=i['geometry']['coordinates'][0][0],\n",
        "            data=merge_zips,\n",
        "            columns=['lat', 'lng', 'Vehicle Count'],\n",
        "            key_on='geometry.coordinates',\n",
        "            fill_color='magma',\n",
        "            line_color='magma'\n",
        "        ).add_to(mapit)\n",
        "# mapit.save('test.html')\n",
        "# coordinates = []\n",
        "# for zip_code in zip_code_count['ZIPCODE']:\n",
        "#     print(zip_code)\n",
        "#     geocode_result = geopandas.\n",
        "    # geocode_result = gmaps.geocode(zip_code)\n",
        "    # lat = geocode_result[0][‘geometry’][‘location’][‘lat’]\n",
        "    # lng = geocode_result[0][‘geometry’][‘location’][‘lng’]\n",
        "    # coordinates.append((lat, lng))"
      ],
      "id": "d1275a55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{python} fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.boxplot(ax=axes[0], data=zip_code_count, x=zip_code_count['Vehicle Count'])\n",
        "log_zip_code_count = zip_code_count.copy()\n",
        "log_zip_code_count['Vehicle Count'] = np.log(zip_code_count['Vehicle Count'])\n",
        "sns.boxplot(ax=axes[1], data=log_zip_code_count, x=log_zip_code_count['Vehicle Count'])\n",
        "```\n",
        "\n",
        "MAKE AND ELECTRIC VEHICLE TYPE"
      ],
      "id": "3dcd15f5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.set_style('darkgrid')\n",
        "make_ev_type = df.groupby(['Make']).agg({\n",
        "    'Vehicle Count': 'sum',\n",
        "}).reset_index()\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.histplot(ax=axes[0], data=make_ev_type, y=make_ev_type['Vehicle Count'])\n",
        "log_make_ev_type = make_ev_type.copy()\n",
        "log_make_ev_type['Vehicle Count'] = np.log(make_ev_type['Vehicle Count'])\n",
        "sns.histplot(ax=axes[1], data=log_make_ev_type, y=log_make_ev_type['Vehicle Count'])"
      ],
      "id": "561a587f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.boxplot(ax=axes[0], data=make_ev_type)\n",
        "log_make_ev_type = make_ev_type.copy()\n",
        "log_make_ev_type['Vehicle Count'] = np.log(make_ev_type['Vehicle Count'])\n",
        "sns.boxplot(ax=axes[1], data=log_make_ev_type)"
      ],
      "id": "afbb669a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MAKE AND Clean Alt Fuel"
      ],
      "id": "12010fc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.set_style('darkgrid')\n",
        "make_ev_type = df.groupby(['Make', 'Clean Alternative Fuel Vehicle (CAFV) Eligibility']).agg({\n",
        "    'Vehicle Count': 'sum',\n",
        "}).reset_index()\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.histplot(ax=axes[0], data=make_ev_type, y=make_ev_type['Vehicle Count'])\n",
        "log_make_ev_type = make_ev_type.copy()\n",
        "log_make_ev_type['Vehicle Count'] = np.log(make_ev_type['Vehicle Count'])\n",
        "sns.histplot(ax=axes[1], data=log_make_ev_type, y=log_make_ev_type['Vehicle Count'])"
      ],
      "id": "88ebb7d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "sns.boxplot(ax=axes[0], data=make_ev_type, x=make_ev_type['Clean Alternative Fuel Vehicle (CAFV) Eligibility'], y=make_ev_type['Vehicle Count'])\n",
        "log_make_ev_type = make_ev_type.copy()\n",
        "log_make_ev_type['Vehicle Count'] = np.log(make_ev_type['Vehicle Count'])\n",
        "sns.boxplot(ax=axes[1], data=log_make_ev_type, x=make_ev_type['Clean Alternative Fuel Vehicle (CAFV) Eligibility'], y=log_make_ev_type['Vehicle Count'])"
      ],
      "id": "90f2680a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mean "
      ],
      "id": "7323f375"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "brand_df = df[[\n",
        " 'Residential energy tax credit amount', 'Total income amount', 'Vehicle Count'\n",
        "]]\n",
        "\n",
        "fig, axes = plt.subplots(1, 1, figsize=(15,15))\n",
        "sns.heatmap(data=brand_df)\n",
        "brand_df.corr()\n",
        "# brand_df['Electric Range'] = np.log(brand_df['Electric Range'])\n",
        "# sns.boxplot(ax=axes[1], data=brand_df, y=brand_df['Electric Range'])"
      ],
      "id": "e9500b2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_brand_df  = df.groupby(['ZIPCODE']).agg({\n",
        "    'Total income amount': 'sum',\n",
        "    'Electric Range': 'count'\n",
        "}).reset_index(drop=True).rename(columns={\n",
        "    'Electric Range': 'Vehicle Count'\n",
        "})\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15,15))\n",
        "new_brand_df['Total income amount'] = new_brand_df['Total income amount'].astype(int)\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(new_brand_df['Total income amount'],new_brand_df['Vehicle Count'])\n",
        "sns.regplot(ax=axes[0], data=new_brand_df, y='Vehicle Count', x='Total income amount', \n",
        "    ci=None, \n",
        "    label=f\"y={0:.1f}x+{1:.1f}\\nr-sq: {r_value.round(3)}\".format(slope, intercept)).legend(loc=\"best\")\n",
        "new_brand_df['Vehicle Count'] = np.log(new_brand_df['Vehicle Count'])\n",
        "new_brand_df['Total income amount'] = np.log(new_brand_df['Total income amount'])\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(new_brand_df['Total income amount'],new_brand_df['Vehicle Count'])\n",
        "sns.regplot(ax=axes[1],\n",
        "    data=new_brand_df,\n",
        "    x='Total income amount',\n",
        "    y='Vehicle Count', \n",
        "    ci=None, \n",
        "    label=f\"y={0:.1f}x+{1:.1f}\\nr-sq: {r_value.round(3)}\".format(slope, intercept)).legend(loc=\"best\")"
      ],
      "id": "0662e72b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "base_dir = '../../'\n",
        "df = read_csv(base_dir + 'data/processed-data/brand_model_year_tax_data.csv')\n",
        "columns_list = df.columns.tolist()\n",
        "for i in columns_list:\n",
        "    print(i.strip())\n",
        "# numeric_cols = columns_list[28:]\n",
        "# df.columns.tolist()"
      ],
      "id": "96bc45f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ZIP CODE ONLY"
      ],
      "id": "56ccfe3a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "amount_brand_df = df.groupby(['ZIPCODE'])[numeric_cols].mean(numeric_only=True).reset_index()\n",
        "brand_df = df.groupby(['ZIPCODE']).agg({\n",
        "    'Vehicle Count': 'sum',\n",
        "    'Electric Range': 'mean'\n",
        "}).reset_index()\n",
        "merged_df = merge(brand_df, amount_brand_df, on=['ZIPCODE'])\n",
        "merged_df = merged_df.sort_values('Vehicle Count', ascending=False)\n",
        "\n",
        "X_df = merged_df\n",
        "Y_df = merged_df[['Vehicle Count']]\n",
        "\n",
        "Y_df = np.log(Y_df)\n",
        "X_df = merged_df.drop(['Vehicle Count', 'Electric Range', 'ZIPCODE'], axis=1)\n",
        "\n",
        "X = np.array(X_df)\n",
        "x = sm.add_constant(X)\n",
        "Y = np.array(Y_df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,Y, \n",
        "                                   random_state=104,  \n",
        "                                   test_size=0.2,\n",
        "                                   shuffle=True) \n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n",
        "results.summary()\n",
        "\n",
        "p_values = results.pvalues\n",
        "p_df = DataFrame()\n",
        "p_df['Feature'] = X_df.columns\n",
        "p_df['p-value'] = results.pvalues[1:]\n",
        "feat_list = []\n",
        "p_val_list = []\n",
        "for idx, row in p_df.iterrows():\n",
        "    if row['p-value'] < .05:\n",
        "        feat_list.append(row['Feature'])\n",
        "        p_val_list.append(row['p-value'])\n",
        "    else:\n",
        "        continue\n",
        "new_p_df = DataFrame()\n",
        "new_p_df['Feature'] = feat_list\n",
        "new_p_df['p-value'] = p_val_list\n",
        "X = np.array(X_df[new_p_df['Feature']])\n",
        "Y = np.array(Y_df)\n",
        "x = sm.add_constant(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,Y, \n",
        "                                   random_state=104,  \n",
        "                                   test_size=0.2,\n",
        "                                   shuffle=True) \n",
        "model2 = sm.OLS(y_train, X_train)\n",
        "results2 = model2.fit()\n",
        "results2.summary()\n",
        "\n",
        "p3_values = results2.pvalues\n",
        "new3 = DataFrame()\n",
        "new3['Feature'] = new_p_df['Feature']\n",
        "new3['p-value'] = p3_values[1:]\n",
        "new3\n",
        "feat_list3 = []\n",
        "p_val_list3 = []\n",
        "for idx, row in new3.iterrows():\n",
        "    if row['p-value'] < .05:\n",
        "        feat_list3.append(row['Feature'])\n",
        "        p_val_list3.append(row['p-value'])\n",
        "    else:\n",
        "        continue\n",
        "final3_df = DataFrame()\n",
        "final3_df['Feature'] = feat_list3\n",
        "final3_df['p-value'] = p_val_list3\n",
        "final3_df\n",
        "X = np.array(X_df[final3_df['Feature']])\n",
        "Y = np.array(Y_df)\n",
        "x = sm.add_constant(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,Y, \n",
        "                                   random_state=104,  \n",
        "                                   test_size=0.2,\n",
        "                                   shuffle=True) \n",
        "\n",
        "model3 = sm.OLS(y_train, X_train)\n",
        "results3 = model3.fit()\n",
        "Y_pred = results3.predict(X_train).astype(int)\n",
        "\n",
        "\n",
        "features = ['constant'] + final3_df['Feature'].tolist()\n",
        "X = DataFrame(X_train, columns=features)\n",
        "Y = DataFrame(y_train, columns=['Vehicle Count'])\n",
        "dataframe = concat([X, Y], axis=1)\n",
        "dataframe\n",
        "results3.summary()\n",
        "features"
      ],
      "id": "e1cc4371",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# model values\n",
        "model_fitted_y = results3.fittedvalues\n",
        "\n",
        "# model residuals\n",
        "model_residuals = results3.resid\n",
        "\n",
        "# normalized residuals\n",
        "model_norm_residuals = results3.get_influence().resid_studentized_internal\n",
        "\n",
        "# absolute squared normalized residuals\n",
        "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
        "\n",
        "# absolute residuals\n",
        "model_abs_resid = np.abs(model_residuals)\n",
        "\n",
        "# leverage, from statsmodels internals\n",
        "model_leverage = results3.get_influence().hat_matrix_diag\n",
        "\n",
        "# cook's distance, from statsmodels internals\n",
        "model_cooks = results3.get_influence().cooks_distance[0]\n",
        "\n",
        "plot_lm_1 = plt.figure()\n",
        "plot_lm_1.axes[0] = sns.residplot(x=model_fitted_y, y=dataframe.columns[-1], data=dataframe,\n",
        "                          lowess=True,\n",
        "                          scatter_kws={'alpha': 0.5},\n",
        "                          line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "\n",
        "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
        "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
        "plot_lm_1.axes[0].set_ylabel('Residuals')\n",
        "df = DataFrame()\n",
        "df['res'] = model_residuals\n",
        "df['fitted'] = model_fitted_y\n",
        "df['count'] = dataframe['Vehicle Count']\n",
        "# df['ZIPCODE'] = dataframe['ZIPCODE']\n",
        "maxr = np.max(model_residuals)\n",
        "df.sort_values('fitted', ascending=False)"
      ],
      "id": "89638b31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normal Q-Q Plot\n",
        "This plot shows if the residuals are normally distributed. A good normal QQ plot has all of the residuals lying on or close to the red line.\n"
      ],
      "id": "0513bd8f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "QQ = ProbPlot(model_norm_residuals)\n",
        "plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
        "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
        "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
        "plot_lm_2.axes[0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "# annotations\n",
        "abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
        "abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
        "for r, i in enumerate(abs_norm_resid_top_3):\n",
        "    plot_lm_2.axes[0].annotate(i,\n",
        "                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],\n",
        "                                   model_norm_residuals[i]))"
      ],
      "id": "3a4b41db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scale-Location\n",
        "This plot is a way to check if the residuals suffer from non-constant variance, aka heteroscedasticity.\n"
      ],
      "id": "930e8fc8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_lm_3 = plt.figure()\n",
        "plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\n",
        "sns.regplot(\n",
        "    x=model_fitted_y, \n",
        "    y=model_norm_residuals_abs_sqrt,\n",
        "    scatter=False,\n",
        "    ci=False,\n",
        "    lowess=True,\n",
        "    line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "plot_lm_3.axes[0].set_title('Scale-Location')\n",
        "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
        "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')\n",
        "\n",
        "# annotations\n",
        "abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)\n",
        "abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
        "for r, i in enumerate(abs_sq_norm_resid_top_3):\n",
        "    plot_lm_3.axes[0].annotate(\n",
        "        i,\n",
        "        xy=(model_fitted_y[i],\n",
        "        model_norm_residuals_abs_sqrt[i]))"
      ],
      "id": "ac2837f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Residuals vs. Leverage\n",
        "Unlike outliers, which have an unusually large y value, leverage points have extreme x values. This may not seem so bad at face value, but it can have damaging effects on the model because the β coefficients are very sensitive to leverage points. The purpose of the Residuals vs Leverage plot is to identify these problematic observations.\n"
      ],
      "id": "f70744e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_lm_4 = plt.figure()\n",
        "plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\n",
        "sns.regplot(x=model_leverage, y=model_norm_residuals,\n",
        "            scatter=False,\n",
        "            ci=False,\n",
        "            lowess=True,\n",
        "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "plot_lm_4.axes[0].set_xlim(0, np.max(model_leverage)+0.01)\n",
        "plot_lm_4.axes[0].set_ylim(-3, 5)\n",
        "plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
        "plot_lm_4.axes[0].set_xlabel('Leverage')\n",
        "plot_lm_4.axes[0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "# annotations\n",
        "leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
        "for i in leverage_top_3:\n",
        "    plot_lm_4.axes[0].annotate(i,\n",
        "                                xy=(model_leverage[i],\n",
        "                                    model_norm_residuals[i]))"
      ],
      "id": "b8056776",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def cookdplot(model, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    cooks_d = model.get_influence().cooks_distance[0]\n",
        "            \n",
        "    ax.vlines(range(len(cooks_d)),0,cooks_d)\n",
        "\n",
        "    # annotations\n",
        "    cookd_top_3 = np.flip(np.argsort(cooks_d), 0)[:3]\n",
        "    for i in cookd_top_3:\n",
        "        ax.annotate(i, xy=(i, cooks_d[i]),color = 'C3')\n",
        "        \n",
        "    ax.set_title(\"Cook's Distance\" , fontweight=\"bold\")\n",
        "    ax.set_xlabel('Obs. Number')\n",
        "    ax.set_ylabel(\"Cook's distance\")\n",
        "    return ax\n",
        "\n",
        "cookdplot(results3)\n",
        "plt.show()"
      ],
      "id": "22d98ead",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SECOND MODEL"
      ],
      "id": "aac3fff7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merged_df = merged_df.loc[(merged_df['Vehicle Count'] != 1.94591)]\n",
        "# print(merged_df.loc[merged_df['Vehicle Count'] < 5].sort_values('Vehicle Count', ascending=False).head(30))\n",
        "X_df = merged_df.copy()\n",
        "Y_df = merged_df[['Vehicle Count']]\n",
        "Y_df = np.log(Y_df)\n",
        "\n",
        "X_features = [\n",
        "#  'Adjust gross income (AGI) [8]',\n",
        "#  'Total income amount',\n",
        " 'State and local income tax refunds amount',\n",
        "#  'Taxable pensions and annuities amount',\n",
        " 'Number of farm returns',\n",
        " 'Total statutory adjustments amount',\n",
        " 'Self-employed (Keogh) retirement plans amount',\n",
        " 'Total standard deduction amount',\n",
        "#  'Basic standard deduction amount',\n",
        "#  'Additional standard deduction amount',\n",
        "#  'Total medical and dental expense deduction amount',\n",
        " 'Limited state and local taxes',\n",
        " 'Home mortgage from personal seller amount',\n",
        " 'Alternative minimum tax amount',\n",
        " 'Child and dependent care credit amount',\n",
        "#  'Net premium tax credit amount',\n",
        "#  'Qualified sick and family leave credit for leave taken before April 1, 2021 amount',\n",
        "#  'Credited to next year’s estimated tax amount'\n",
        " ]\n",
        "X_df = X_df[X_features]\n",
        "feat_list = []\n",
        "log_list = []\n",
        "for feat in X_features:\n",
        "    feat_list.append(feat)\n",
        "    log_list.append(np.log(X_df[feat]))\n",
        "\n",
        "\n",
        "\n",
        "# X_features = ['ZIPCODE',\n",
        "#  'Adjust gross income (AGI) [8]',\n",
        "#  'Total income amount',\n",
        "#  'Total statutory adjustments amount',\n",
        "#  'Home mortgage from personal seller amount',\n",
        "#  'Alternative minimum tax amount']\n",
        "\n",
        "X = X_df[X_features]\n",
        "\n",
        "Y = Y_df\n",
        "x = sm.add_constant(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,Y, \n",
        "                                   random_state=104,  \n",
        "                                   test_size=0.2,\n",
        "                                   shuffle=True) \n",
        "\n",
        "print(X_train)\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results2mod = model.fit()\n",
        "# Y_pred = results2mod.predict(X_test).astype(int)\n",
        "results2mod.summary()\n",
        "model1 = LinearRegression().fit(X_train, y_train)\n",
        "model1.score(X_train, y_train)\n",
        "# model1.score(X_test, y_test)\n",
        "# results2mod.summary()\n",
        "\n",
        "X = DataFrame(X_train, columns=['constant'] + X_features)\n",
        "Y = DataFrame(y_train, columns=['Vehicle Count'])\n",
        "dataframe = concat([X, Y], axis=1)\n",
        "# dataframe\n",
        "results2mod.summary()\n",
        "# model1 = LinearRegression().fit(X_train, y_train)\n",
        "# model1.score(X_train, y_train)\n",
        "# model1.score(X_test, y_test)\n",
        "# model.coef_\n",
        "# model.intercept_\n",
        "# Y_pred = model1.predict(X_test)\n",
        "# plt.scatter(x=y_test, y=Y_pred)\n",
        "# plt.plot(y_test, Y_pred, color='red')    \n",
        "# sns.regplot(x=y_test, y=Y_pred)"
      ],
      "id": "5f372bf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_# model values\n",
        "model_fitted_y = results2mod.fittedvalues\n",
        "\n",
        "# model residuals\n",
        "model_residuals = results2mod.resid\n",
        "\n",
        "# normalized residuals\n",
        "model_norm_residuals = results2mod.get_influence().resid_studentized_internal\n",
        "\n",
        "# absolute squared normalized residuals\n",
        "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
        "\n",
        "# absolute residuals\n",
        "model_abs_resid = np.abs(model_residuals)\n",
        "\n",
        "# leverage, from statsmodels internals\n",
        "model_leverage = results2mod.get_influence().hat_matrix_diag\n",
        "print(model_leverage)\n",
        "\n",
        "# cook's distance, from statsmodels internals\n",
        "model_cooks = results2mod.get_influence().cooks_distance[0]\n",
        "\n",
        "plot_lm_1 = plt.figure()\n",
        "plot_lm_1.axes[0] = sns.residplot(x=model_fitted_y, y=dataframe.columns[-1], data=dataframe,\n",
        "                          lowess=True,\n",
        "                          scatter_kws={'alpha': 0.5},\n",
        "                          line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "\n",
        "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
        "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
        "plot_lm_1.axes[0].set_ylabel('Residuals')\n",
        "df = DataFrame()\n",
        "df['res'] = model_residuals\n",
        "df['fitted'] = model_fitted_y\n",
        "df['count'] = dataframe['Vehicle Count']\n",
        "df['index'] = df.index\n",
        "maxr = np.max(model_residuals)\n",
        "df.sort_values('res', ascending=True)"
      ],
      "id": "032f528c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normal Q-Q Plot\n",
        "This plot shows if the residuals are normally distributed. A good normal QQ plot has all of the residuals lying on or close to the red line.\n"
      ],
      "id": "c1eac155"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "QQ = ProbPlot(model_norm_residuals)\n",
        "plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
        "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
        "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
        "plot_lm_2.axes[0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "# annotations\n",
        "abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
        "abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
        "for r, i in enumerate(abs_norm_resid_top_3):\n",
        "    plot_lm_2.axes[0].annotate(i,\n",
        "                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],\n",
        "                                   model_norm_residuals[i]))"
      ],
      "id": "f1623f8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scale-Location\n",
        "This plot is a way to check if the residuals suffer from non-constant variance, aka heteroscedasticity.\n"
      ],
      "id": "26e5a45b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_lm_3 = plt.figure()\n",
        "plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\n",
        "sns.regplot(\n",
        "    x=model_fitted_y, \n",
        "    y=model_norm_residuals_abs_sqrt,\n",
        "    scatter=False,\n",
        "    ci=False,\n",
        "    lowess=True,\n",
        "    line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "plot_lm_3.axes[0].set_title('Scale-Location')\n",
        "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
        "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')\n",
        "\n",
        "# annotations\n",
        "abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)\n",
        "abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
        "for r, i in enumerate(abs_sq_norm_resid_top_3):\n",
        "    plot_lm_3.axes[0].annotate(\n",
        "        i,\n",
        "        xy=(model_fitted_y[i],\n",
        "        model_norm_residuals_abs_sqrt[i]))"
      ],
      "id": "a2d020a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Residuals vs. Leverage\n",
        "Unlike outliers, which have an unusually large y value, leverage points have extreme x values. This may not seem so bad at face value, but it can have damaging effects on the model because the β coefficients are very sensitive to leverage points. The purpose of the Residuals vs Leverage plot is to identify these problematic observations.\n"
      ],
      "id": "400b7ffd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_lm_4 = plt.figure()\n",
        "plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\n",
        "sns.regplot(x=model_leverage, y=model_norm_residuals,\n",
        "            scatter=False,\n",
        "            ci=False,\n",
        "            lowess=True,\n",
        "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
        "plot_lm_4.axes[0].set_xlim(0, np.max(model_leverage)+0.01)\n",
        "plot_lm_4.axes[0].set_ylim(-3, 5)\n",
        "plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
        "plot_lm_4.axes[0].set_xlabel('Leverage')\n",
        "plot_lm_4.axes[0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "# annotations\n",
        "leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
        "for i in leverage_top_3:\n",
        "    plot_lm_4.axes[0].annotate(i,\n",
        "                                xy=(model_leverage[i],\n",
        "                                    model_norm_residuals[i]))"
      ],
      "id": "dd62847d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def cookdplot(model, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    cooks_d = model.get_influence().cooks_distance[0]\n",
        "            \n",
        "    ax.vlines(range(len(cooks_d)),0,cooks_d)\n",
        "\n",
        "    # annotations\n",
        "    cookd_top_3 = np.flip(np.argsort(cooks_d), 0)[:3]\n",
        "    for i in cookd_top_3:\n",
        "        ax.annotate(i, xy=(i, cooks_d[i]),color = 'C3')\n",
        "        \n",
        "    ax.set_title(\"Cook's Distance\" , fontweight=\"bold\")\n",
        "    ax.set_xlabel('Obs. Number')\n",
        "    ax.set_ylabel(\"Cook's distance\")\n",
        "    return ax\n",
        "\n",
        "cookdplot(results2mod)\n",
        "plt.show()"
      ],
      "id": "db10e103",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}